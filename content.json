{"meta":{"title":"Su's Blog","subtitle":"Day Day Up","description":null,"author":"SuQ","url":"http://yoursite.com"},"pages":[{"title":"","date":"2017-07-28T07:42:04.000Z","updated":"2017-07-28T07:42:04.000Z","comments":true,"path":"readme.html","permalink":"http://yoursite.com/readme.html","excerpt":"","text":"部署三部曲： hexo clean hexo generate #生成静态页面到public目录 hexo deploy #部署.deploy项目到github 常用命令： hexo new “postName” #新建文章 hexo new page “pagename” #新建页面"},{"title":"categories","date":"2017-07-29T08:13:55.000Z","updated":"2017-07-29T08:14:41.000Z","comments":true,"path":"categories/index.html","permalink":"http://yoursite.com/categories/index.html","excerpt":"","text":""},{"title":"about","date":"2017-07-29T08:17:54.000Z","updated":"2017-07-29T08:17:54.000Z","comments":true,"path":"about/index.html","permalink":"http://yoursite.com/about/index.html","excerpt":"","text":""},{"title":"tags","date":"2017-07-29T08:18:21.000Z","updated":"2017-07-29T08:19:12.000Z","comments":false,"path":"tags/index.html","permalink":"http://yoursite.com/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"正则表达式","slug":"正则表达式","date":"2017-09-04T09:45:41.000Z","updated":"2017-09-04T10:57:41.000Z","comments":true,"path":"2017/09/04/正则表达式/","link":"","permalink":"http://yoursite.com/2017/09/04/正则表达式/","excerpt":"正则表达式相关注解(1)数量词的贪婪模式与非贪婪模式正则表达式通常用于在文本中查找匹配的字符串。Python里数量词默认是贪婪的（在少数语言里也可能是默认非贪婪），总是尝试匹配尽可能多的字符；非贪婪的则相反，总是尝试匹配尽可能少的字符。例如：正则表达式”ab”如果用于查找”abbbc”，将找到”abbb”。而如果使用非贪婪的数量词”ab?”，将找到”a”。 注：我们一般使用非贪婪模式来提取。","text":"正则表达式相关注解(1)数量词的贪婪模式与非贪婪模式正则表达式通常用于在文本中查找匹配的字符串。Python里数量词默认是贪婪的（在少数语言里也可能是默认非贪婪），总是尝试匹配尽可能多的字符；非贪婪的则相反，总是尝试匹配尽可能少的字符。例如：正则表达式”ab”如果用于查找”abbbc”，将找到”abbb”。而如果使用非贪婪的数量词”ab?”，将找到”a”。 注：我们一般使用非贪婪模式来提取。 (2)反斜杠问题与大多数编程语言相同，正则表达式里使用”\\”作为转义字符，这就可能造成反斜杠困扰。假如你需要匹配文本中的字符”\\”，那么使用编程语言表示的正则表达式里将需要4个反斜杠”\\\\”：前两个和后两个分别用于在编程语言里转义成反斜杠，转换成两个反斜杠后再在正则表达式里转义成一个反斜杠。 Python里的原生字符串很好地解决了这个问题，这个例子中的正则表达式可以使用r”\\”表示。同样，匹配一个数字的”\\d”可以写成r”\\d”。有了原生字符串，妈妈也不用担心是不是漏写了反斜杠，写出来的表达式也更直观勒。 正则表达式的语法规则 ####","categories":[],"tags":[{"name":"正则表达式","slug":"正则表达式","permalink":"http://yoursite.com/tags/正则表达式/"}]},{"title":"python中cookie的用法","slug":"python中cookie的用法","date":"2017-09-04T09:11:01.000Z","updated":"2017-09-04T11:46:33.000Z","comments":true,"path":"2017/09/04/python中cookie的用法/","link":"","permalink":"http://yoursite.com/2017/09/04/python中cookie的用法/","excerpt":"（来自http://cuiqingcai.com/968.html ，基于python2） 当你获取一个URL你使用一个opener(一个urllib2.OpenerDirector的实例)。在前面，我们都是使用的默认的opener，也就是urlopen。它是一个特殊的opener，可以理解成opener的一个特殊实例，传入的参数仅仅是url，data，timeout。 如果我们需要用到Cookie，只用这个opener是不能达到目的的，所以我们需要创建更一般的opener来实现对Cookie的设置。","text":"（来自http://cuiqingcai.com/968.html ，基于python2） 当你获取一个URL你使用一个opener(一个urllib2.OpenerDirector的实例)。在前面，我们都是使用的默认的opener，也就是urlopen。它是一个特殊的opener，可以理解成opener的一个特殊实例，传入的参数仅仅是url，data，timeout。 如果我们需要用到Cookie，只用这个opener是不能达到目的的，所以我们需要创建更一般的opener来实现对Cookie的设置。 cookielib模块的主要作用是提供可存储cookie的对象，以便于与urllib2模块配合使用来访问Internet资源。Cookielib模块非常强大，我们可以利用本模块的CookieJar类的对象来捕获cookie并在后续连接请求时重新发送，比如可以实现模拟登录功能。该模块主要的对象有CookieJar、FileCookieJar、MozillaCookieJar、LWPCookieJar。 它们的关系：CookieJar —-派生—-&gt;FileCookieJar —-派生—–&gt;MozillaCookieJar和LWPCookieJar 123456789101112131415161718192021222324'''对于python3.4 cookie结构图: CookieJar / \\ \\ FileCookieJar \\ \\ / | \\ \\ \\ MozillaCookieJar | LWPCookieJar \\ \\ | | \\ | ---MSIEBase | \\ | / | | \\ | / MSIEDBCookieJar BSDDBCookieJar |/ MSIECookieJar ''' 获取Cookie保存到变量首先，我们先利用CookieJar对象实现获取cookie的功能，存储到变量中 12345678910111213141516171819202122232425262728293031323334353637383940414243444546import urllib.requestimport http.cookiejar# python3的http.cookiejar相对于python2是cookielibif __name__ == '__main__': # 声明一个CookieJar对象实例来保存cookie cookie = http.cookiejar.CookieJar() # 利用HTTPCookieProcessor对象来创建cookie处理器 handler = urllib.request.HTTPCookieProcessor(cookie) # 通过handler来构建opener opener = urllib.request.build_opener(handler) response = opener.open(\"http://www.baidu.com\") for item in cookie: print('name = ' + item.name) print('value = ' + item.value)'''打印的结果name = BAIDUIDvalue = D604445C0C028E8ABE4264EC0CBD7E1D:FG=1name = BIDUPSIDvalue = D604445C0C028E8ABE4264EC0CBD7E1Dname = H_PS_PSSIDvalue = 1466_21089_22159name = PSTMvalue = 1504509252name = BDSVRTMvalue = 0name = BD_HOMEvalue = 0''''''基于python2的代码import urllib2import cookielibcookie = cookielib.CookieJar()#利用urllib2库的HTTPCookieProcessor对象来创建cookie处理器handler=urllib2.HTTPCookieProcessor(cookie)#通过handler来构建openeropener = urllib2.build_opener(handler)#此处的open方法同urllib2的urlopen方法，也可以传入requestresponse = opener.open('http://www.baidu.com')for item in cookie: print 'Name = '+item.name print 'Value = '+item.value ''' 保存Cookie到文件在上面的方法中，我们将cookie保存到了cookie这个变量中，如果我们想将cookie保存到文件中该怎么做呢？这时，我们就要用到 FileCookieJar这个对象了，在这里我们使用它的子类MozillaCookieJar来实现Cookie的保存。 12345678910111213141516171819202122232425262728293031import urllib.requestimport http.cookiejarif __name__ == '__main__': # 设置保存cookie的文件，同级目录下的cookie.txt filename = 'cookie.txt' # 声明一个MozillaCookieJar对象实例来保存cookie，之后写入文件 cookie = http.cookiejar.MozillaCookieJar(filename) handler = urllib.request.HTTPCookieProcessor(cookie) opener = urllib.request.build_opener(handler) response = opener.open(\"http://www.baidu.com\") # 保存cookie到文件 cookie.save(ignore_discard=True, ignore_expires=True) ''' ignore_discard: save even cookies set to be discarded.(即使cookies将被丢弃也将它保留下来) ignore_expires: save even cookies that have expired the file is overwritten if it already exists (若cookies已经存在，就覆盖原文件写入) ''' ''' cookie.txt的内容 # Netscape HTTP Cookie File # http://curl.haxx.se/rfc/cookie_spec.html # This is a generated file! Do not edit. .baidu.com TRUE / FALSE 3651994080 BAIDUID 5CEA0A924FE72079A5C5E4F66704297F:FG=1 .baidu.com TRUE / FALSE 3651994080 BIDUPSID 5CEA0A924FE72079A5C5E4F66704297F .baidu.com TRUE / FALSE H_PS_PSSID 1458_21105_18560_20927 .baidu.com TRUE / FALSE 3651994080 PSTM 1504510433 www.baidu.com FALSE / FALSE BDSVRTM 0 www.baidu.com FALSE / FALSE BD_HOME 0 ''' 从文件中获取Cookie并访问1234567891011def usecookie(): # 创建MozillaCookieJar实例对象 newcookie = http.cookiejar.MozillaCookieJar() # 从文件中读取cookie内容到变量 newcookie.load('cookie.txt', ignore_expires=True, ignore_discard=True) # 创建请求的request req = urllib.request.Request(\"http://www.baidu.com\") # 利用build_opener创建一个opener newopener = urllib.request.build_opener(urllib.request.HTTPCookieProcessor(newcookie)) resp = newopener.open(req) print(resp.read()) 利用cookie模拟登录豆瓣123456789101112131415161718192021filename = 'cookie.txt'# disable SSL verification, since it is default in python 2.7.9ssl._create_default_https_context = ssl._create_unverified_context# 声明一个MozillaCookieJar对象实例来保存cookie，之后写入文件cookie = http.cookiejar.MozillaCookieJar(filename)handler = urllib.request.HTTPCookieProcessor(cookie)opener = urllib.request.build_opener(handler)''' 数据编码，否则报错TypeError: POST data should be bytes, an iterable of bytes, or a file object. It cannot be of type str.'''data = urllib.parse.urlencode(&#123; 'form_email': '18883325578', 'form_password': '我的密码'&#125;).encode()url = \"https://accounts.douban.com/login\"response = opener.open(url, data)# 保存cookie到文件cookie.save(ignore_discard=True, ignore_expires=True)result = opener.open(\"http://www.douban.com\")soup = BeautifulSoup(result.read())print(soup) 要点: Python 2.7.9 之后版本引入了一个新特性，当你urllib.urlopen一个 https 的时候会验证一次 SSL 证书,当目标使用的是自签名的证书时就会爆出一个urllib.URLError: 的错误消息","categories":[],"tags":[{"name":"cookie","slug":"cookie","permalink":"http://yoursite.com/tags/cookie/"}]},{"title":"cookies详解","slug":"cookies详解","date":"2017-09-04T06:40:47.000Z","updated":"2017-09-04T06:45:37.000Z","comments":true,"path":"2017/09/04/cookies详解/","link":"","permalink":"http://yoursite.com/2017/09/04/cookies详解/","excerpt":"(来自 http://blog.csdn.net/u012175089/article/details/70054806) HTTP cookies，通常又称作”cookies”早期Web开发面临的最大问题之一是如何管理状态。服务器端没有办法知道两个请求是否来自于同一个浏览器。那时的办法是在请求的页面中插入一个token，并且在下一次请求中将这个token返回（至服务器）。这就需要在form中插入一个包含token的隐藏表单域，或着在URL的qurey字符串中传递该token。这两种办法都强调手工操作并且极易出错。cookies工作原理的基本信息在RFC2109中被规范化。","text":"(来自 http://blog.csdn.net/u012175089/article/details/70054806) HTTP cookies，通常又称作”cookies”早期Web开发面临的最大问题之一是如何管理状态。服务器端没有办法知道两个请求是否来自于同一个浏览器。那时的办法是在请求的页面中插入一个token，并且在下一次请求中将这个token返回（至服务器）。这就需要在form中插入一个包含token的隐藏表单域，或着在URL的qurey字符串中传递该token。这两种办法都强调手工操作并且极易出错。cookies工作原理的基本信息在RFC2109中被规范化。 cookie是什么？一个cookie就是存储在用户主机浏览器中的一小段文本文件。Cookies是纯文本形式，它们不包含任何可执行代码。一个Web页面或服务器告之浏览器来将这些信息存储并且基于一系列规则在之后的每个请求中都将该信息返回至服务器。Web服务器之后可以利用这些信息来标识用户。 – 通过HTTP的Set-Cookie消息头，Web服务器可以指定存储一个cookie。Set-Cookie消息的格式如下面的字符串（中括号中的部分都是可选的）Set-Cookie:value [ ;expires=date][ ;domain=domain][ ;path=path][ ;secure]value部分，通常是一个name=value格式的字符串。事实上有很多浏览器用自己的格式，有细微的不同。当一个cookie存在，并且可选条件允许的话，该cookie的值会在接下来的每个请求中被发送至服务器。 cookie的值被存储在名为Cookie的HTTP消息头中，并且只包含了cookie的值，其它的选项全部被去除。可选项只是存在于浏览器端，并不需要发给服务端。例如： Cookie : value如果在指定的请求中有多个cookies，那么它们会被分号和空格分开，例如：Cookie:value1 ; value2 ; name1=value1 有效期选项（The expires option）指定了cookie过期的时间，过期后可能会被浏览器删掉。格式为Wdy,DD-Mon–YYYY HH:MM:SS GMT，例如：Set-Cookie:name=Nicholas;expires=Sat, 02 May 2009 23:38:25 GMT在没有expires选项时，cookie的寿命仅限于单一的会话中。浏览器的关闭意味这一次会话的结束，所以会话cookie只存在于浏览器保持打开的状态之下。 domain选项（The domain option）指示cookie将要发送到哪个域或那些域中。默认情况下，domain会被设置为创建该cookie的页面所在的域名。domain选项被用来扩展cookie值所要发送域的数量。例如:Set-Cookie:name=Nicholas;domain=www.baidu.com很多时候大网站存在二级域名，例如fanyi.baidu.com。cookies可能只发给对应的二级域名。 Path选项（The path option）在请求相匹配的路径的时候，才会发送cookie例如：Set-Cookie:name=Nicholas;path=/blog在这个例子中，path选项值会与/blog,/blogrool等等相匹配；任何以/blog开头的选项都是合法的。 secure选项（The secure option）该选项只是一个标记并且没有其它的值。只有当请求是通过SSL和HTTPS创建时，才会发送。这种cookie的内容意指具有很高的价值并且可能潜在的被破解以纯文本形式传输。例如Set-Cookie:name=Nicholas;secure现实中，机密且敏感的信息绝不应该在cookies中存储或传输，因为cookies的整个机制都是原本不安全的。默认情况下，在HTTPS链接上传输的cookies都会被自动添加上secure选项。 cookie的维护和生命周期（cookie maintenance and lifecycle）任意数量的选项都可以在单一的cookie中指定，并且这些选项可以以任何顺序存在，例如Set-Cookie:name=Nicholas; domain=nczonline.net; path=/blog这个cooke有四个标识符：cookie的name，domain，path，secure标记。要想在将来改变这个cookie的值，需要发送另一个具有相同cookie name,domain,path的Set-Cookie消息头。例如：Set-Cooke:name=Greg; domain=nczonline.net; path=/blog这将以一个新的值来覆盖原来cookie的值。然而，仅仅只是改变这些选项的某一个也会创建一个完全不同的cookie，例如：Set-Cookie:name=Nicholas; domain=nczonline.net; path=/在返回这个消息头后，会存在两个同时拥有“name”的不同的cookie。如果你访问在www.nczonline.NET/blog下的一个页面，以下的消息头将被包含进来：Cookie：name=Greg;name=Nicholas在这个消息头中存在了两个名为“name”的cookie，path值越详细则cookie越靠前。domain-path越详细则cookie字符串越靠前。假设我在ww.nczonline.Net/blog下并且发送了另一个cookie，其设置如下：Set-Cookie:name=Mike那么返回的消息头现在则变为：Cookie：name=Mike;name=Greg;name=Nicholas由于包含“Mike”的cookie使用了域名（www.nczonline.net）作为其domain值并且以全路径（/blog）作为其path值，则它较其它两个cookie更加详细。 使用失效日期（using expiration dates）当cookie创建时包含了失效日期，这个失效日期则关联了以name-domain-path-secure为标识的cookie。要改变一个cookie的失效日期，必须指定同样的组合。当改变一个cookie的值时，你不必每次都设置失效日期，因为它不是cookie标识信息的组成部分。例如：Set-Cookie:name=Mike;expires=Sat,03 May 2025 17:44:22 GMT现在已经设置了cookie的失效日期，所以下次我想要改变cookie的值时，我只需要使用它的名字：Set-Cookie:name=Matt在cookie上的失效日期并没有改变，因为cookie的标识符是相同的。实际上，只有你手工的改变cookie的失效日期，否则其失效日期不会改变。这意味着在同一个会话中，一个会话cookie可以变成一个持久化cookie（一个可以在多个会话中存在的），反之则不可。为了要将一个持久化cookie变为一个会话cookie，你必须删除这个持久化cookie，这只要设置它的失效日期为过去某个时间之后再创建一个同名的会话cookie就可以实现。需要记得的是失效日期是以浏览器运行的电脑上的系统时间为基准进行核实的。没有任何办法来来验证这个系统时间是否和服务器的时间同步，所以当服务器时间和浏览器所处系统时间存在差异时这样的设置会出现错误。 cookie自动删除（automatic cookie removal）cookie会被浏览器自动删除，通常存在以下几种原因：会话cooke(Session cookie)在会话结束时（浏览器关闭）会被删除持久化cookie（Persistent cookie）在到达失效日期时会被删除如果浏览器中的cookie限制到达，那么cookies会被删除以为新建cookies创建空间。对于任何这些自动删除来说，Cookie管理显得十分重要，因为这些删除都是无意识的。 Cookie限制条件（Cookie restrictions）在cookies上存在了诸多限制条件，来阻止cookie滥用并保护浏览器和服务器免受一些负面影响。有两种cookies的限制条件：cookies的属性和cookies的总大小。原始的规范中限定每个域名下不超过20个cookies，早期的浏览器都遵循该规范，并且在IE7中有个更近一步的提升。在微软的一次更新中，他们在IE7中增加cookies的限制到50个，与此同时Opera限定cookies个数为30.Safari和Chrome对与每个域名下的cookies个数没有限制。发向服务器的所有cookies的最大数量（空间）仍旧维持原始规范中所指出的：4KB。所有超出该限制的cookies都会被截掉并且不会发送至服务器。Subcookies鉴于cookie的数量限制，开发者提出的subcookies的观点来增加cookies的存储量。Subcookies是一些存储在一个cookie的value中的一些name-value对，并且通常与以下格式类似：name=a=b&amp;c=d&amp;e=f&amp;g=h这种方式允许在单个cookie中保存多个name-value对，而不会超过浏览器cookie的数量限制。通过这种方式创建cookies的负面影响是，需要自定义解析方式来提取这些值，相比较而言cookies的格式会更为简单。服务器端框架已开始支持subcookies的存储。","categories":[],"tags":[{"name":"cookie","slug":"cookie","permalink":"http://yoursite.com/tags/cookie/"}]},{"title":"cookie的用法","slug":"pythonbasic","date":"2017-09-02T03:22:16.000Z","updated":"2017-09-04T09:45:19.000Z","comments":true,"path":"2017/09/02/pythonbasic/","link":"","permalink":"http://yoursite.com/2017/09/02/pythonbasic/","excerpt":"","text":"python cookie的使用（来自http://cuiqingcai.com/968.html ，基于python2） 当你获取一个URL你使用一个opener(一个urllib2.OpenerDirector的实例)。在前面，我们都是使用的默认的opener，也就是urlopen。它是一个特殊的opener，可以理解成opener的一个特殊实例，传入的参数仅仅是url，data，timeout。 如果我们需要用到Cookie，只用这个opener是不能达到目的的，所以我们需要创建更一般的opener来实现对Cookie的设置。 &lt;!— more —&gt; cookielib模块的主要作用是提供可存储cookie的对象，以便于与urllib2模块配合使用来访问Internet资源。Cookielib模块非常强大，我们可以利用本模块的CookieJar类的对象来捕获cookie并在后续连接请求时重新发送，比如可以实现模拟登录功能。该模块主要的对象有CookieJar、FileCookieJar、MozillaCookieJar、LWPCookieJar。 它们的关系：CookieJar —-派生—-&gt;FileCookieJar —-派生—–&gt;MozillaCookieJar和LWPCookieJar 获取Cookie保存到变量首先，我们先利用CookieJar对象实现获取cookie的功能，存储到变量中 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061'''对于python3.4 cookie结构图: CookieJar / \\ \\ FileCookieJar \\ \\ / | \\ \\ \\ MozillaCookieJar | LWPCookieJar \\ \\ | | \\ | ---MSIEBase | \\ | / | | \\ | / MSIEDBCookieJar BSDDBCookieJar |/ MSIECookieJar '''import urllib.requestimport http.cookiejar# python3的http.cookiejar相对于python2是cookielibif __name__ == '__main__': # 声明一个CookieJar对象实例来保存cookie cookie = http.cookiejar.CookieJar() # 利用HTTPCookieProcessor对象来创建cookie处理器 handler = urllib.request.HTTPCookieProcessor(cookie) # 通过handler来构建opener opener = urllib.request.build_opener(handler) response = opener.open(\"http://www.baidu.com\") for item in cookie: print('name = ' + item.name) print('value = ' + item.value)'''打印的结果name = BAIDUIDvalue = D604445C0C028E8ABE4264EC0CBD7E1D:FG=1name = BIDUPSIDvalue = D604445C0C028E8ABE4264EC0CBD7E1Dname = H_PS_PSSIDvalue = 1466_21089_22159name = PSTMvalue = 1504509252name = BDSVRTMvalue = 0name = BD_HOMEvalue = 0''''''基于python2的代码import urllib2import cookielibcookie = cookielib.CookieJar()#利用urllib2库的HTTPCookieProcessor对象来创建cookie处理器handler=urllib2.HTTPCookieProcessor(cookie)#通过handler来构建openeropener = urllib2.build_opener(handler)#此处的open方法同urllib2的urlopen方法，也可以传入requestresponse = opener.open('http://www.baidu.com')for item in cookie: print 'Name = '+item.name print 'Value = '+item.value ''' 保存Cookie到文件在上面的方法中，我们将cookie保存到了cookie这个变量中，如果我们想将cookie保存到文件中该怎么做呢？这时，我们就要用到 FileCookieJar这个对象了，在这里我们使用它的子类MozillaCookieJar来实现Cookie的保存。 12345678910111213141516171819202122232425262728293031import urllib.requestimport http.cookiejarif __name__ == '__main__': # 设置保存cookie的文件，同级目录下的cookie.txt filename = 'cookie.txt' # 声明一个MozillaCookieJar对象实例来保存cookie，之后写入文件 cookie = http.cookiejar.MozillaCookieJar(filename) handler = urllib.request.HTTPCookieProcessor(cookie) opener = urllib.request.build_opener(handler) response = opener.open(\"http://www.baidu.com\") # 保存cookie到文件 cookie.save(ignore_discard=True, ignore_expires=True) ''' ignore_discard: save even cookies set to be discarded.(即使cookies将被丢弃也将它保留下来) ignore_expires: save even cookies that have expired the file is overwritten if it already exists (若cookies已经存在，就覆盖原文件写入) ''' ''' cookie.txt的内容 # Netscape HTTP Cookie File # http://curl.haxx.se/rfc/cookie_spec.html # This is a generated file! Do not edit. .baidu.com TRUE / FALSE 3651994080 BAIDUID 5CEA0A924FE72079A5C5E4F66704297F:FG=1 .baidu.com TRUE / FALSE 3651994080 BIDUPSID 5CEA0A924FE72079A5C5E4F66704297F .baidu.com TRUE / FALSE H_PS_PSSID 1458_21105_18560_20927 .baidu.com TRUE / FALSE 3651994080 PSTM 1504510433 www.baidu.com FALSE / FALSE BDSVRTM 0 www.baidu.com FALSE / FALSE BD_HOME 0 ''' 从文件中获取Cookie并访问1234567891011def usecookie(): # 创建MozillaCookieJar实例对象 newcookie = http.cookiejar.MozillaCookieJar() # 从文件中读取cookie内容到变量 newcookie.load('cookie.txt', ignore_expires=True, ignore_discard=True) # 创建请求的request req = urllib.request.Request(\"http://www.baidu.com\") # 利用build_opener创建一个opener newopener = urllib.request.build_opener(urllib.request.HTTPCookieProcessor(newcookie)) resp = newopener.open(req) print(resp.read()) 利用cookie模拟登录豆瓣123456789101112131415161718192021filename = 'cookie.txt'# disable SSL verification, since it is default in python 2.7.9ssl._create_default_https_context = ssl._create_unverified_context# 声明一个MozillaCookieJar对象实例来保存cookie，之后写入文件cookie = http.cookiejar.MozillaCookieJar(filename)handler = urllib.request.HTTPCookieProcessor(cookie)opener = urllib.request.build_opener(handler)''' 数据编码，否则报错TypeError: POST data should be bytes, an iterable of bytes, or a file object. It cannot be of type str.'''data = urllib.parse.urlencode(&#123; 'form_email': '18883325578', 'form_password': '我的密码'&#125;).encode()url = \"https://accounts.douban.com/login\"response = opener.open(url, data)# 保存cookie到文件cookie.save(ignore_discard=True, ignore_expires=True)result = opener.open(\"http://www.douban.com\")soup = BeautifulSoup(result.read())print(soup) 要点: Python 2.7.9 之后版本引入了一个新特性，当你urllib.urlopen一个 https 的时候会验证一次 SSL 证书,当目标使用的是自签名的证书时就会爆出一个urllib.URLError: 的错误消息","categories":[],"tags":[{"name":"cookie","slug":"cookie","permalink":"http://yoursite.com/tags/cookie/"}]},{"title":"About Yield","slug":"About-Yield","date":"2017-08-11T06:32:42.000Z","updated":"2017-08-11T06:32:42.000Z","comments":true,"path":"2017/08/11/About-Yield/","link":"","permalink":"http://yoursite.com/2017/08/11/About-Yield/","excerpt":"写python遇到yield不是很懂。。。网上搜罗了一番 yield在python中作为生成器理解，主要用处是可以迭代，简化了很多运算模型。 yield是一个表达式，是有返回值的，如果说函数中含有yield时，它将不再是一个普通的函数，而是一个生成器，当该函数被调用时，不会自动执行，而是暂停。工作原理就是通过重复调用next()方法，直到捕获异常。yield 是一个类似 return 的关键字，迭代一次遇到yield时就返回yield后面的值。重点是：下一次迭代时，从上一次迭代遇到的yield后面的代码开始执行。","text":"写python遇到yield不是很懂。。。网上搜罗了一番 yield在python中作为生成器理解，主要用处是可以迭代，简化了很多运算模型。 yield是一个表达式，是有返回值的，如果说函数中含有yield时，它将不再是一个普通的函数，而是一个生成器，当该函数被调用时，不会自动执行，而是暂停。工作原理就是通过重复调用next()方法，直到捕获异常。yield 是一个类似 return 的关键字，迭代一次遇到yield时就返回yield后面的值。重点是：下一次迭代时，从上一次迭代遇到的yield后面的代码开始执行。 yield起源于对一般function中return的扩展，在一个function，必须有一个返回值列于return之后，且return意味中function的结束，一旦结束之后，函数里面的变量将被全部抛弃，如果需要让函数暂停下来，并返回当前所在地方的值，接收到后面的命令时又继续前进。 就像菲波那切数列，它是一个自循环数列，按照循环算法需要很大的运算量，同时，也并不知道何时会停下运算，如果采用动态记录的话，就会非常简单： 123456789101112131415161718192021222324252627282930313233343536373839404142434445#菲波那切数列：每一个数都等于前两个数的和def fib(to = 10): curr = 0 next = 1 count = 0 while count &lt; to: yield curr curr = next next = curr + next count += 1if __name__ == '__main__': for x in fib(10): print(x + 1)#得到的值 \"\"\"12359173365129257\"\"\"#另一个例子&gt;&gt;&gt; def fun2(): print 'first' yield 5 print 'second' yield 23 print 'end...' &gt;&gt;&gt; g1 = fun2() &gt;&gt;&gt; g1.next() #第一次运行,暂停在yield 5 first 5 &gt;&gt;&gt; g1.next() #第二次运行,暂停在yield 23 second 23 &gt;&gt;&gt; g1.next() #第三次运行,由于之后没有yield,再次next()就会抛出错误 end... Traceback (most recent call last): File \"&lt;stdin&gt;\", line 1, in &lt;module&gt; StopIteration ps：未完待续。。。","categories":[{"name":"study","slug":"study","permalink":"http://yoursite.com/categories/study/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://yoursite.com/tags/Python/"}]},{"title":"关于threading","slug":"关于threading","date":"2017-08-10T08:38:30.000Z","updated":"2017-08-11T08:32:31.000Z","comments":true,"path":"2017/08/10/关于threading/","link":"","permalink":"http://yoursite.com/2017/08/10/关于threading/","excerpt":"threading模块包含的方法python中的threading模块包含了一下的一些方法： threading.acitve_count()返回正在运行的线程对象的个数，返回的个数和enumerate()方法返回的线程列表长度一致。 threading.current_thread()返回当前线程对象。如果调用者的控制线程不是通过threading模块创建的，将会返回被限制功能的虚拟线程对象 threading.get_indent()返回当前线程的线程标识符，它的值没有实际意义。 threading.enumerate()返回当前运行中的线程列表，包括守护线程、主线程，由current_thread（）创建的虚拟线程。不包括终止的线程和尚未启动的线程。 threading.main_thread()返回主线程对象，在正常情况下，主线程是有python解释器开始的线程","text":"threading模块包含的方法python中的threading模块包含了一下的一些方法： threading.acitve_count()返回正在运行的线程对象的个数，返回的个数和enumerate()方法返回的线程列表长度一致。 threading.current_thread()返回当前线程对象。如果调用者的控制线程不是通过threading模块创建的，将会返回被限制功能的虚拟线程对象 threading.get_indent()返回当前线程的线程标识符，它的值没有实际意义。 threading.enumerate()返回当前运行中的线程列表，包括守护线程、主线程，由current_thread（）创建的虚拟线程。不包括终止的线程和尚未启动的线程。 threading.main_thread()返回主线程对象，在正常情况下，主线程是有python解释器开始的线程 ​ … Thread对象Thread类是一种在单独的控制线程中运行的活动，只有两种方法来具象这个活动：给构造函数传递一个可调用对象，或者在子类中覆盖run()方法。在这个类中国年只有__init__()和run()方法可以被覆盖。 一旦线程对象被创建，必须通过调用start()方法来开启线程活动，将会调用另一个单独的控制线程中的run()方法。 线程只有被启动就会处于活跃状态，只有在run()终止或者诱发了一个未处理的异常才会终止线程，可以使用is_alive()方法来检测线程是否处于活跃状态。 join()方法将会阻止线程的调用，直到调用join()方法的线程终止。 线程有名字，可以传递给构造函数，并通过该属性读取或者修改线程名。 class threading.Thread(group=None, target=None, name=None, args=(), kwargs={}, **, daemon=None*) 如果子类覆盖了构造函数，那么必须在对线程操作前调用基类构造函数的Thread.__init__()方法。 start()启动线程，每个线程最多且必须调用一次 run()表示线程活动的方法。 join()等待线程终止。 name() getName() setName() ident() is_alive() daemon()一个布尔值，指示此线程是否为守护线程（True）或否（False）。这必须在start()被调用之前设置。主线程不是守护线程，因此在主线程中创建的所有线程都默认为daemon= False。 isDaemon() setDaemon() 参考：https://docs.python.org/3.6/library/threading.html 代码示例： 1234567891011121314151617181920212223242526272829303132333435363738# -*- coding:utf-8 -*-import threadingclass threadpro (threading.Thread):#继承父类的threading.Thread def __init__(self,threadID, name): threading.Thread.__init__(self) self.threadID = threadID self.name = name def run(self):#表示线程活动的方法，线程创建后直接运行run函数 print('------\\nstarting ' + self.name) print(threading.active_count())#查看当前活跃的进程数 for i in range(threading.active_count()): print(threading.enumerate()[i].getName())#打印进程名 print(\"Exiting \" + self.name )threadpool = []thread1 = threadpro(1,'thread-1')thread2 = threadpro(2,'thread-2')threadpool.append(thread1)threadpool.append(thread2)thread1.start()thread2.start()#结果#------#starting thread-1#2#MainThread#thread-1#Exiting thread-1#------#starting thread-2#2#MainThread#thread-2#Exiting thread-2","categories":[],"tags":[{"name":"Python","slug":"Python","permalink":"http://yoursite.com/tags/Python/"}]},{"title":"Beautiful Soup","slug":"Beautiful-Soup","date":"2017-08-09T02:55:39.000Z","updated":"2017-08-11T03:41:11.000Z","comments":true,"path":"2017/08/09/Beautiful-Soup/","link":"","permalink":"http://yoursite.com/2017/08/09/Beautiful-Soup/","excerpt":"一、简介 Beautiful Soup是一个可以从HTML或XML文件中提取数据的Python库，能够通过喜欢的转换器实现管用的文档导航，查找，修改文档的方式。Beautiful Soup提供一些简单的、python式的函数用来处理导航、搜索、修改分析树等功能，它是一个工具箱，通过解析文档为用户提供需要抓取的数据，因为简单，所以不需要多少代码就可以写出一个完成的应用程序。Beautiful Soup自动将输入文档转换为unicode编码，输出文档转换为utf-8编码。","text":"一、简介 Beautiful Soup是一个可以从HTML或XML文件中提取数据的Python库，能够通过喜欢的转换器实现管用的文档导航，查找，修改文档的方式。Beautiful Soup提供一些简单的、python式的函数用来处理导航、搜索、修改分析树等功能，它是一个工具箱，通过解析文档为用户提供需要抓取的数据，因为简单，所以不需要多少代码就可以写出一个完成的应用程序。Beautiful Soup自动将输入文档转换为unicode编码，输出文档转换为utf-8编码。例如当一段HTML代码被多次用到，用BeautifulSoup解这段HTML代码， 可以实现标准的缩进格式的代码。 以下是示例 123456789101112131415161718192021222324252627282930313233343536from bs4 import BeautifulSoupsoup = BeautifulSoup(html_doc)print(soup.prettify())# &lt;html&gt;# &lt;head&gt;# &lt;title&gt;# The Dormouse's story# &lt;/title&gt;# &lt;/head&gt;# &lt;body&gt;# &lt;p class=\"title\"&gt;# &lt;b&gt;# The Dormouse's story# &lt;/b&gt;# &lt;/p&gt;# &lt;p class=\"story\"&gt;# Once upon a time there were three little sisters; and their names were# &lt;a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\"&gt;# Elsie# &lt;/a&gt;# ,# &lt;a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\"&gt;# Lacie# &lt;/a&gt;# and# &lt;a class=\"sister\" href=\"http://example.com/tillie\" id=\"link2\"&gt;# Tillie# &lt;/a&gt;# ; and they lived at the bottom of a well.# &lt;/p&gt;# &lt;p class=\"story\"&gt;# ...# &lt;/p&gt;# &lt;/body&gt;# &lt;/html&gt; 从文档中找所有标签的链接： 12345for link in soup.find_all('a'): print(link.get('href')) # http://example.com/elsie # http://example.com/lacie # http://example.com/tillie 从文档中获取所有文字内容： 123456789101112print(soup.get_text())# The Dormouse's story## The Dormouse's story## Once upon a time there were three little sisters; and their names were# Elsie,# Lacie and# Tillie;# and they lived at the bottom of a well.## ... 二、使用方法将一段文档传入BeautifulSoup的构造方法，从而得到一个文档对象。 123from bs4 import BeautifulSoupsoup = BeautifulSoup(open('index.html'))soup = BeautifulSoup(\"&lt;html&gt;data&lt;/html&gt;\") Beautiful Soup将复杂HTML文档转换成一个复杂的树形结构,每个节点都是Python对象,所有对象可以归纳为4种: Tag , NavigableString , BeautifulSoup , Comment .","categories":[],"tags":[]},{"title":"someproblemsimet","slug":"someproblemsimet","date":"2017-08-06T10:29:02.000Z","updated":"2017-08-07T02:02:25.000Z","comments":true,"path":"2017/08/06/someproblemsimet/","link":"","permalink":"http://yoursite.com/2017/08/06/someproblemsimet/","excerpt":"","text":"python 解决NAMEError：name ‘reload’ is not defined的问题 对于python 2.x: 123import sysreload(sys)sys.setdefaultencoding(\"utf-8\") 对于python&lt;=3.3: 12345import impimp.reload(sys)'''python3与python 2有很大的区别，python3系统默认使用的是UTF-8编码，所以，对于使用的是python3的情况不需要使用sys.setdefaultencoding('utf-8')这段代码，并且python3中已经没有setdefaultencoding这个函数了 ''' 对于python&gt;=3.4: 12import importlibimportlib.reload(sys) 在python3中已经没有StringIO模块，修改为io模块","categories":[],"tags":[]},{"title":"About urllib2","slug":"About-urllib2","date":"2017-07-31T02:54:56.000Z","updated":"2017-07-31T02:54:56.000Z","comments":true,"path":"2017/07/31/About-urllib2/","link":"","permalink":"http://yoursite.com/2017/07/31/About-urllib2/","excerpt":"","text":"","categories":[{"name":"study","slug":"study","permalink":"http://yoursite.com/categories/study/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://yoursite.com/tags/Python/"}]},{"title":"Hello World","slug":"hello-world","date":"2017-07-27T03:42:57.000Z","updated":"2017-07-27T03:42:57.000Z","comments":true,"path":"2017/07/27/hello-world/","link":"","permalink":"http://yoursite.com/2017/07/27/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[],"tags":[]}]}